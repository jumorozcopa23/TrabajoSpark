{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrege acá el código para importar las librerias\n",
    "\n",
    "# La libreria para \"encontrar el sevicio\" de Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Librerias para \"gestionar el servicio\" de Spark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Creamos una aplicación Spark en el Servicio\n",
    "# Tenga cuidado con las tildes o caracteres especiales en el nombre de la app\n",
    "AppSpark = SparkConf().setAppName(\"Evaluacion iSofware\")\n",
    "\n",
    "# definimos un espacio o contexto para la App\n",
    "ContextoSpark=SparkContext(conf=AppSpark)\n",
    "\n",
    "# inicio una sesión en el espacio de la App\n",
    "SesionSpark = SparkSession(ContextoSpark)\n",
    "\n",
    "# inicio del espacio o contexto SQL\n",
    "ContextoSql = SQLContext(sparkContext=ContextoSpark, sparkSession=SesionSpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/tmp/Asistencia.csv': File exists\n",
      "copyFromLocal: `/tmp/Evaluacion.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargue los datos en la carpeta datalake y luego del /datalake al HDFS (Hadoop File System)\n",
    "# Recuerda usar ! para ejecutar el comando en el shell. \n",
    "# Tu código a continuación...\n",
    "\n",
    "#!hdfs dfs -ls\n",
    "!hdfs dfs -copyFromLocal Asistencia.csv /tmp/\n",
    "!hdfs dfs -copyFromLocal Evaluacion.csv /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup      93121 2021-05-26 15:40 /tmp/Asistencia.csv\n",
      "-rw-r--r--   1 root supergroup     111944 2021-05-26 15:40 /tmp/Evaluacion.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/*csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cree dos tablas SparkSQL y almacene el csv en su correspondiente tabla.\n",
    "# Observación: tenga especial cuidado con los encabezados de los archivos CSV.\n",
    "# Usted puede considerar cambiar los encabezados de los CSV originales\n",
    "# Tu código a continuación...\n",
    "asis = SesionSpark.read.load('/tmp/Asistencia.csv',format=\"csv\",sep=',',inferSchema='true',header='true')\n",
    "eva = SesionSpark.read.load('/tmp/Evaluacion.csv',format=\"csv\",sep=',',inferSchema='true',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tiempo: string (nullable = true)\n",
      " |-- usuario: string (nullable = true)\n",
      " |-- equipoPertenece: string (nullable = true)\n",
      " |-- equipoExponer: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Validamos datos cambiando el nombre de las columnas\n",
    "asis1 = asis.withColumnRenamed(\"Marca temporal\", \"tiempo\")\n",
    "asis2 = asis1.withColumnRenamed(\"Nombre de usuario\", \"usuario\")\n",
    "asis3 = asis2.withColumnRenamed(\"Equipo al que perteneces:\", \"equipoPertenece\")\n",
    "asis4 = asis3.withColumnRenamed(\"Equipo que va a exponer:\", \"equipoExponer\")\n",
    "asis4.printSchema()\n",
    "asis = asis4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tiempo: string (nullable = true)\n",
      " |-- usuario: string (nullable = true)\n",
      " |-- equipoEvaluar: string (nullable = true)\n",
      " |-- introduccion: integer (nullable = true)\n",
      " |-- equipo: integer (nullable = true)\n",
      " |-- problema: integer (nullable = true)\n",
      " |-- ventajas: integer (nullable = true)\n",
      " |-- solucion: integer (nullable = true)\n",
      " |-- producto: integer (nullable = true)\n",
      " |-- traccion: integer (nullable = true)\n",
      " |-- mercado: integer (nullable = true)\n",
      " |-- competencia: integer (nullable = true)\n",
      " |-- modeloNegocio: integer (nullable = true)\n",
      " |-- inversion: integer (nullable = true)\n",
      " |-- contacto: integer (nullable = true)\n",
      " |-- exposicion1: integer (nullable = true)\n",
      " |-- exposicion2: integer (nullable = true)\n",
      " |-- exposicion3: integer (nullable = true)\n",
      " |-- supon: string (nullable = true)\n",
      " |-- observacion: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eva2 = eva.withColumnRenamed(\"Marca temporal\",\"tiempo\") \\\n",
    "    .withColumnRenamed(\"Nombre de usuario\",\"usuario\") \\\n",
    "    .withColumnRenamed(\"Equipo que vas a evaluar:\",\"equipoEvaluar\") \\\n",
    "    .withColumnRenamed(\"Ventajas: El equipo responde adecuadamente ¿Por qué su solución es especial?, ¿qué la hace distinta de otras?\",\"ventajas\") \\\n",
    "    .withColumnRenamed(\"Problema: El equipo responde adecuadamente ¿Qué problema resolverá?, ¿es realmente un problema?\",\"problema\") \\\n",
    "    .withColumnRenamed(\"Introducción: El equipo responde adecuadamente ¿Quiénes son y por qué están aquí?\",\"introduccion\") \\\n",
    "    .withColumnRenamed(\"Solución: El equipo responde adecuadamente ¿Cómo piensa resolver el problema?\",\"solucion\") \\\n",
    "    .withColumnRenamed(\"Tracción: El equipo responde adecuadamente si cuenta con clientes que demuestran potencial.\",\"traccion\") \\\n",
    "    .withColumnRenamed(\"Modelo de negocio: El equipo responde adecuadamente ¿Cómo hará dinero? \",\"modeloNegocio\") \\\n",
    "    .withColumnRenamed(\"Inversión: El equipo responde adecuadamente ¿Cuál es su presupuesto y cuánto espera ganar?\",\"inversion\") \\\n",
    "    .withColumnRenamed(\"Exposición: ¿Qué tan coordinados estaban los expositores?\",\"exposicion1\") \\\n",
    "    .withColumnRenamed(\"Exposición: ¿Los expositores se expresaron con claridad y se hicieron entender?\",\"exposicion2\") \\\n",
    "    .withColumnRenamed(\"Exposición: Las diapositivas son claras y coherentes y apoyaron adecuadamente la exposición.\",\"exposicion3\") \\\n",
    "    .withColumnRenamed(\"Suponiendo que eres inversionista, ¿Estarías dispuesto a invertir dinero en este equipo? (esta pregunta no se pondera en la nota)\",\"supon\") \\\n",
    "    .withColumnRenamed(\"Observaciones para el equipo, estas observaciones las debe considerar el equipo para mejorar la siguiente presentación.\",\"observacion\") \\\n",
    "    .withColumnRenamed(\"Contacto: El equipo deja los datos al cliente y muestra cómo pueden contactarle.\",\"contacto\") \\\n",
    "    .withColumnRenamed(\"Competencia: El equipo responde adecuadamente ¿Cuáles son las soluciones alternativas al problema que plantea?\",\"competencia\") \\\n",
    "    .withColumnRenamed(\"Mercado: El equipo responde conoce, o por lo menos intentar predecir, el tamaño del mercado que impactará.\",\"mercado\") \\\n",
    "    .withColumnRenamed(\"Producto: El equipo responde adecuadamente ¿Cómo funciona el producto o servicio? Muestra algunos ejemplos.\",\"producto\") \\\n",
    "    .withColumnRenamed(\"Equipo: El equipo responde adecuadamente ¿Quiénes están detrás de la idea y cuál es su función?\", \"equipo\")\n",
    "eva = eva2\n",
    "eva2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de asistencias:  662  y total de evaluaciones:  617 .\n"
     ]
    }
   ],
   "source": [
    "#Datos adicionales\n",
    "totalAsis = asis.count()\n",
    "totalEva = eva.count()\n",
    "print('Total de asistencias: ', totalAsis, ' y total de evaluaciones: ', totalEva, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             usuario|\n",
      "+--------------------+\n",
      "| abanolc@unal.edu.co|\n",
      "|acastrillonv@unal...|\n",
      "| aflemag@unal.edu.co|\n",
      "|anapariciom@unal....|\n",
      "|angutierrezb@unal...|\n",
      "|anoriega@unal.edu.co|\n",
      "|auarbelaeza@unal....|\n",
      "| bocampo@unal.edu.co|\n",
      "|cgiraldo@unal.edu.co|\n",
      "|cjfunezg@unal.edu.co|\n",
      "|cquinchiar@unal.e...|\n",
      "| dadazam@unal.edu.co|\n",
      "|daestradam@unal.e...|\n",
      "|davgarciava@unal....|\n",
      "|dballesteroso@una...|\n",
      "|  dbrito@unal.edu.co|\n",
      "|dcadavid@unal.edu.co|\n",
      "|dcardonaal@unal.e...|\n",
      "|dchavarriar@unal....|\n",
      "|dgarciabl@unal.ed...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Consulte el listado total de estudiantes (correos electrónicos) del \n",
    "# curso de Ingeniería de Software, ordenados alfabéticamente\n",
    "# Tu código a continuación...\n",
    "\n",
    "#um = asis.sort(['usuario']).select(['usuario']).drop_duplicates().count()\n",
    "#Respuesta\n",
    "asis.sort(['usuario']).select(['usuario']).drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|             usuario|count(usuario)|\n",
      "+--------------------+--------------+\n",
      "|samolinap@unal.ed...|            10|\n",
      "| jruedat@unal.edu.co|             8|\n",
      "|nvalenciat@unal.e...|             8|\n",
      "|serendona@unal.ed...|             8|\n",
      "|jgutierrezlo@unal...|             8|\n",
      "|dgerenal@unal.edu.co|             8|\n",
      "|cjfunezg@unal.edu.co|             8|\n",
      "|emflorezb@unal.ed...|             8|\n",
      "|dchavarriar@unal....|             8|\n",
      "|fguerrerot@unal.e...|             8|\n",
      "|jdroldano@unal.ed...|             1|\n",
      "|juriveras@unal.ed...|             8|\n",
      "|jovillarrealm@una...|            10|\n",
      "|dguardia@unal.edu.co|             8|\n",
      "| lrdiaza@unal.edu.co|             7|\n",
      "|fmiranda@unal.edu.co|             8|\n",
      "|dcadavid@unal.edu.co|             8|\n",
      "| bocampo@unal.edu.co|             8|\n",
      "|rmbuilesm@unal.ed...|             9|\n",
      "|jmunozhe@unal.edu.co|             8|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Consulte la cantidad de asistencias registradas por estudiante; además, la fecha y hora de la primera asistencia\n",
    "# y la fecha y hora de la última asistencia\n",
    "# Tu código a continuación...\n",
    "\n",
    "################ FALTA ESTE PUNTO ############################\n",
    "from pyspark.sql import functions as F\n",
    "asis.groupBy('usuario').agg(F.count('usuario')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Consulte el listado de estudiantes que asistieron a 2 presentaciones o menos (una).\n",
    "# Tu código a continuación...\n",
    "\n",
    "#Creamos una vista para trabajar con SQL\n",
    "asis.createOrReplaceTempView('vistaAsis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             usuario|total|\n",
      "+--------------------+-----+\n",
      "|jdroldano@unal.ed...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Respuesta\n",
    "SesionSpark.sql(\"\"\"\n",
    " select usuario, total from (select usuario, count(usuario) as total from vistaAsis group by usuario) where total <= 2\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Consulte el listado de estudiantes que no asistieron a ninguna presentación.\n",
    "# Tu código a continuación...\n",
    "\n",
    "#Creamos otra vista para trabajar con SQL\n",
    "eva.createOrReplaceTempView('vistaEva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             usuario|\n",
      "+--------------------+\n",
      "| que genera un có...|\n",
      "|                null|\n",
      "|                null|\n",
      "| o las imágenes c...|\n",
      "| hasta más famoso...|\n",
      "| poder ver gráfic...|\n",
      "|                null|\n",
      "| ya que no se le ...|\n",
      "|                null|\n",
      "|                null|\n",
      "| parece publicida...|\n",
      "|                null|\n",
      "|                null|\n",
      "| como todo buen e...|\n",
      "|                null|\n",
      "|                null|\n",
      "|    UberEats incluso|\n",
      "| pueden incluir a...|\n",
      "| por el hecho de ...|\n",
      "| es un gasto que ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Respuesta\n",
    "SesionSpark.sql(\"\"\"\n",
    " select E.usuario from vistaEva E left join vistaAsis A on E.usuario = A.usuario where A.usuario is null\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SesionSpark.sql(\"\"\"\n",
    " select E.usuario from vistaEva E left join vistaAsis A on E.usuario = A.usuario where A.usuario is null\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|     equipoPertenece|count(usuario)|\n",
      "+--------------------+--------------+\n",
      "|Pertenezco a: Ges...|            84|\n",
      "|Pertenezco a: Lo ...|            87|\n",
      "|Pertenezco a: Adm...|            95|\n",
      "|Pertenezco a: Ser...|            65|\n",
      "|Pertenezco a: Te ...|            89|\n",
      "|Pertenezco a: Ges...|            86|\n",
      "|Pertenezco a: Ges...|            73|\n",
      "|Pertenezco a: Mi ...|            83|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Consulte los integrantes por cada equipo al que pertenecen.\n",
    "# Tu código a continuación...\n",
    "\n",
    "#Respuesta\n",
    "SesionSpark.sql(\"\"\"\n",
    " select equipoPertenece, count(usuario) from vistaAsis group by equipoPertenece\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|     equipoPertenece|count(usuario)|\n",
      "+--------------------+--------------+\n",
      "|Pertenezco a: Ges...|            84|\n",
      "|Pertenezco a: Lo ...|            87|\n",
      "|Pertenezco a: Adm...|            95|\n",
      "|Pertenezco a: Ser...|            65|\n",
      "|Pertenezco a: Te ...|            89|\n",
      "|Pertenezco a: Ges...|            86|\n",
      "|Pertenezco a: Ges...|            73|\n",
      "|Pertenezco a: Mi ...|            83|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Consulte la cantidad de asistentes por presentación, sin considerar los asistentes que pertenecen \n",
    "# al equipo que realizó la presentación.\n",
    "# Tu código a continuación...\n",
    "\n",
    "#Respuesta\n",
    "SesionSpark.sql(\"\"\"\n",
    " select equipoPertenece, count(usuario) from vistaAsis where equipoPertenece <> equipoExponer group by equipoPertenece \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+\n",
      "|usuario|perteneceA|equipoEvaluar|\n",
      "+-------+----------+-------------+\n",
      "+-------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Consutar cuáles integrantes evaluaron a su propio equipo. Estas evaluaciones no serán válidas, pues un\n",
    "# integrante no puede evaluar a su propio equipo.\n",
    "# Tu código a continuación...\n",
    "\n",
    "#Respuesta\n",
    "SesionSpark.sql(\"\"\"\n",
    " select * from (select A.usuario, SUBSTRING(A.equipoPertenece, 14) AS perteneceA, E.equipoEvaluar from vistaAsis A inner join vistaEva E on A.usuario = E.usuario) where perteneceA = equipoEvaluar\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`introduccion`' given input columns: [vistaasis.tiempo, vistaasis.usuario, vistaasis.equipoPertenece, vistaasis.equipoExponer]; line 3 pos 5;\\n'Project ['avg('introduccion) AS promIntroduccion#646, 'avg('equipo) AS promEquipo#647, 'avg('problema) AS promProblema#648, 'avg('ventajas) AS promVentajas#649, 'avg('solucion) AS promSolucion#650, 'avg('producto) AS promProducto#651, 'avg('traccion) AS promTraccion#652, 'avg('mercado) AS promMercado#653, 'avg('competencia) AS promCompetencia#654, 'avg('modeloNegocio) AS PromModeloNegiocio#655, 'avg('inversion) AS promInversion#656, 'avg('contacto) AS promContacto#657, 'avg('exposicion1) AS promExposicion1#658, 'avg('exposicion2) AS promExposicion2#659, 'avg('exposicion3) AS promExposicion3#660]\\n+- SubqueryAlias `vistaasis`\\n   +- Project [tiempo#68, usuario#73, equipoPertenece#78, Equipo que va a exponer:#13 AS equipoExponer#83]\\n      +- Project [tiempo#68, usuario#73, Equipo al que perteneces:#12 AS equipoPertenece#78, Equipo que va a exponer:#13]\\n         +- Project [tiempo#68, Nombre de usuario#11 AS usuario#73, Equipo al que perteneces:#12, Equipo que va a exponer:#13]\\n            +- Project [Marca temporal#10 AS tiempo#68, Nombre de usuario#11, Equipo al que perteneces:#12, Equipo que va a exponer:#13]\\n               +- Relation[Marca temporal#10,Nombre de usuario#11,Equipo al que perteneces:#12,Equipo que va a exponer:#13] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o21.sql.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`introduccion`' given input columns: [vistaasis.tiempo, vistaasis.usuario, vistaasis.equipoPertenece, vistaasis.equipoExponer]; line 3 pos 5;\n'Project ['avg('introduccion) AS promIntroduccion#646, 'avg('equipo) AS promEquipo#647, 'avg('problema) AS promProblema#648, 'avg('ventajas) AS promVentajas#649, 'avg('solucion) AS promSolucion#650, 'avg('producto) AS promProducto#651, 'avg('traccion) AS promTraccion#652, 'avg('mercado) AS promMercado#653, 'avg('competencia) AS promCompetencia#654, 'avg('modeloNegocio) AS PromModeloNegiocio#655, 'avg('inversion) AS promInversion#656, 'avg('contacto) AS promContacto#657, 'avg('exposicion1) AS promExposicion1#658, 'avg('exposicion2) AS promExposicion2#659, 'avg('exposicion3) AS promExposicion3#660]\n+- SubqueryAlias `vistaasis`\n   +- Project [tiempo#68, usuario#73, equipoPertenece#78, Equipo que va a exponer:#13 AS equipoExponer#83]\n      +- Project [tiempo#68, usuario#73, Equipo al que perteneces:#12 AS equipoPertenece#78, Equipo que va a exponer:#13]\n         +- Project [tiempo#68, Nombre de usuario#11 AS usuario#73, Equipo al que perteneces:#12, Equipo que va a exponer:#13]\n            +- Project [Marca temporal#10 AS tiempo#68, Nombre de usuario#11, Equipo al que perteneces:#12, Equipo que va a exponer:#13]\n               +- Relation[Marca temporal#10,Nombre de usuario#11,Equipo al que perteneces:#12,Equipo que va a exponer:#13] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:297)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1b74fd90f2ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m  \u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexposicion3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpromExposicion3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m  \u001b[0;32mfrom\u001b[0m \u001b[0mvistaAsis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \"\"\").show()\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#introduccion, equipo, problema, ventajas, solucion, producto, traccion, mercado, competencia, modeloNegocio, inversion, contacto, exposicion1, exposicion2, exposicion3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`introduccion`' given input columns: [vistaasis.tiempo, vistaasis.usuario, vistaasis.equipoPertenece, vistaasis.equipoExponer]; line 3 pos 5;\\n'Project ['avg('introduccion) AS promIntroduccion#646, 'avg('equipo) AS promEquipo#647, 'avg('problema) AS promProblema#648, 'avg('ventajas) AS promVentajas#649, 'avg('solucion) AS promSolucion#650, 'avg('producto) AS promProducto#651, 'avg('traccion) AS promTraccion#652, 'avg('mercado) AS promMercado#653, 'avg('competencia) AS promCompetencia#654, 'avg('modeloNegocio) AS PromModeloNegiocio#655, 'avg('inversion) AS promInversion#656, 'avg('contacto) AS promContacto#657, 'avg('exposicion1) AS promExposicion1#658, 'avg('exposicion2) AS promExposicion2#659, 'avg('exposicion3) AS promExposicion3#660]\\n+- SubqueryAlias `vistaasis`\\n   +- Project [tiempo#68, usuario#73, equipoPertenece#78, Equipo que va a exponer:#13 AS equipoExponer#83]\\n      +- Project [tiempo#68, usuario#73, Equipo al que perteneces:#12 AS equipoPertenece#78, Equipo que va a exponer:#13]\\n         +- Project [tiempo#68, Nombre de usuario#11 AS usuario#73, Equipo al que perteneces:#12, Equipo que va a exponer:#13]\\n            +- Project [Marca temporal#10 AS tiempo#68, Nombre de usuario#11, Equipo al que perteneces:#12, Equipo que va a exponer:#13]\\n               +- Relation[Marca temporal#10,Nombre de usuario#11,Equipo al que perteneces:#12,Equipo que va a exponer:#13] csv\\n\""
     ]
    }
   ],
   "source": [
    "# 9. Consultar la nota promedio por cada ítem (1 al 15), y la nota promedio total del cada equipo. Recuerde que no\n",
    "# son válidas las evaluaciones realizadas por los miembros del mismo equipo.\n",
    "# Tu código a continuación...\n",
    "\n",
    "#Respuesta\n",
    "SesionSpark.sql(\"\"\"\n",
    " select\n",
    " avg(introduccion) as promIntroduccion,\n",
    " avg(equipo) as promEquipo,\n",
    " avg(problema) as promProblema,\n",
    " avg(ventajas) as promVentajas,\n",
    " avg(solucion) as promSolucion,\n",
    " avg(producto) as promProducto,\n",
    " avg(traccion) as promTraccion,\n",
    " avg(mercado) as promMercado,\n",
    " avg(competencia) as promCompetencia,\n",
    " avg(modeloNegocio) as PromModeloNegiocio,\n",
    " avg(inversion) as promInversion,\n",
    " avg(contacto) as promContacto,\n",
    " avg(exposicion1) as promExposicion1,\n",
    " avg(exposicion2) as promExposicion2,\n",
    " avg(exposicion3) as promExposicion3 \n",
    " from vistaAsis  \n",
    "\"\"\").show()\n",
    "\n",
    "#introduccion, equipo, problema, ventajas, solucion, producto, traccion, mercado, competencia, modeloNegocio, inversion, contacto, exposicion1, exposicion2, exposicion3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Consulte el mejor equipo evaluado por cada ítem (según nota promedio. En caso de empate mostrar todos los empatados) \n",
    "# y el mejor equipo según el promedio total.\n",
    "# Tu código a continuación...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Consulte el peor equipo evaluado por cada ítem (según nota promedio. En caso de empate mostrar todos los empatados) \n",
    "# y el peor equipo según el promedio total.\n",
    "# Tu código a continuación...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Consulte la lista de estudiantes con la correspondiente nota obtenida en la presentación \n",
    "# (nota promedio total de la evaluación obtenida por el equipo)\n",
    "# Tu código a continuación...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
